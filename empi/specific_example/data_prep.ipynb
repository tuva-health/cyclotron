{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb21e18-cc82-4fb9-b3dd-cea7319132c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook does exploratory data analysis and cleans data for using Tuva EMPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cfb4bc-6424-4c82-8b47-d0b409c8f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb9eb28-2977-49e0-ae9c-34dd057d8016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv(\"TuvaPatientImportFile_UTF8.txt\", dtype=str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a60e406-794f-4b7d-a70d-8d2b1032e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f7139b-c412-4b56-bfee-c5b5eeb36600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'zipcode' column to 'zip_code' for consistency with Tuva naming convention:\n",
    "df = df.rename(columns={\"zipcode\": \"zip_code\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f3768a-bf04-4ead-87fe-90fd29aa7cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for records with null 'source_person_id'\n",
    "df[df['source_person_id'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6445cba-e3c6-448f-a422-2898732a8f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove records with null 'source_person_id'\n",
    "df = df[df['source_person_id'].notnull()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d4f1dc-bfd1-40e4-8285-32271e87f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at data sources we have to make sure we have data from all expected sources:\n",
    "df['data_source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21779237-6061-4790-b576-17710e73529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates:\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdba2f0-c913-4931-9ffe-d61741e1081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate records and check how many records we have left after:\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93524cfd-2a9c-4534-95fb-ac8d134c48cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'source_person_id','data_source' to see if sometimes\n",
    "# the same person from the same data source can appear in\n",
    "# multiple records with variations in their demographic fields\n",
    "grouped = (\n",
    "    df.groupby(['source_person_id','data_source'])\n",
    "          .size()\n",
    "          .reset_index(name='counter')\n",
    "          .sort_values(by='counter',ascending=False)\n",
    ")\n",
    "\n",
    "grouped.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2d5ec-1254-4efe-af66-6fb17b67b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at an example of a source_person_id that appears on\n",
    "# multiple records, potentially with variations in demographic fields\n",
    "\n",
    "#df[df['source_person_id'] == \"\"]  # fill in value for source_person_id we want to look at here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace61db-a88f-4696-b2bb-1243ba090e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e586839-58f5-4e87-9006-4d21364bf9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform fields for matching, one at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d48909-c2e9-4b55-9ab0-39b1f57ff020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c602289-c2e8-4068-9b9b-607e9cc3090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_person_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a858e37d-0a0c-4c19-969b-963d7e463dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many nulls we have\n",
    "df['source_person_id'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3b7068-16a6-4a80-a3f7-9fa67eec9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many source_person_ids we have of different lengths\n",
    "df['source_person_id'].dropna().astype(str).str.len().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe6b23b-8ce7-4d65-9bb0-aa6ad0db5088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No transformations needed for the field 'source_person_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6332a5-9ea7-444c-9079-b400f303a4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384dc949-2749-47e1-8986-93691f7f5cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9061c4eb-a3be-4c10-9bbc-27d5f6b465eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if the data_source field has null values\n",
    "df['data_source'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b42340-11d1-4049-9e24-135751b6f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the distinct values the data_source field takes:\n",
    "df['data_source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a0e787-49f4-4b27-abaa-3d1ef738167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No transformations needed for the data_source field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d0efb-76b5-450c-a4cd-eff554f6718b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4237a7-82e1-41c8-a172-952f97ee9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06285014-c1a0-4e7d-a5f3-f10bc1c4e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many nulls we have\n",
    "df['first_name'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d719d2a-cac7-4d8c-9975-931236e86154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the 'first_name' field and apply it to the field:\n",
    "\n",
    "def clean_first_name(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    nickname_map = {\n",
    "        \"bob\": \"robert\",\n",
    "        \"bobby\": \"robert\",\n",
    "        \"rob\": \"robert\",\n",
    "        \"robby\": \"robert\",\n",
    "        \"rick\": \"richard\",\n",
    "        \"ricky\": \"richard\",\n",
    "        \"rich\": \"richard\",\n",
    "        \"dick\": \"richard\",\n",
    "        \"bill\": \"william\",\n",
    "        \"billy\": \"william\",\n",
    "        \"will\": \"william\",\n",
    "        \"willy\": \"william\",\n",
    "        \"liz\": \"elizabeth\",\n",
    "        \"beth\": \"elizabeth\",\n",
    "        \"betsy\": \"elizabeth\",\n",
    "        \"lisa\": \"elizabeth\",\n",
    "        \"kate\": \"katherine\",\n",
    "        \"katie\": \"katherine\",\n",
    "        \"kathy\": \"katherine\",\n",
    "        \"jen\": \"jennifer\",\n",
    "        \"jenny\": \"jennifer\",\n",
    "        \"mike\": \"michael\",\n",
    "        \"mikey\": \"michael\",\n",
    "        \"chris\": \"christopher\",\n",
    "        \"topher\": \"christopher\",\n",
    "        \"dan\": \"daniel\",\n",
    "        \"danny\": \"daniel\",\n",
    "        \"steve\": \"steven\",\n",
    "        \"stevie\": \"steven\",\n",
    "        \"jim\": \"james\",\n",
    "        \"jimmy\": \"james\",\n",
    "        \"jamie\": \"james\",\n",
    "        \"johnny\": \"john\",\n",
    "        \"johnnie\": \"john\",\n",
    "        \"jack\": \"john\",\n",
    "        \"andy\": \"andrew\",\n",
    "        \"drew\": \"andrew\",\n",
    "        \"pat\": \"patrick\",\n",
    "        \"trish\": \"patricia\",\n",
    "        \"tricia\": \"patricia\",\n",
    "        \"sam\": \"samuel\",\n",
    "        \"samantha\": \"sam\",\n",
    "        \"toni\": \"antonia\",\n",
    "        \"tony\": \"anthony\",\n",
    "    }\n",
    "\n",
    "    def normalize_name(name):\n",
    "        if pd.isnull(name):\n",
    "            return None\n",
    "        # Lowercase and strip\n",
    "        name = name.lower().strip()\n",
    "        # Normalize accented characters\n",
    "        name = unicodedata.normalize(\"NFKD\", name).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "        # Remove non-alpha characters\n",
    "        name = re.sub(r\"[^a-z\\s\\-]\", \"\", name)\n",
    "        # Collapse whitespace\n",
    "        name = re.sub(r\"\\s+\", \" \", name)\n",
    "        # Map nickname\n",
    "        if name in nickname_map:\n",
    "            name = nickname_map[name]\n",
    "        # Return None if empty\n",
    "        return name if name else None\n",
    "\n",
    "    df[\"first_name\"] = df[\"first_name\"].apply(normalize_name)\n",
    "    return df\n",
    "\n",
    "df = clean_first_name(df)\n",
    "df['first_name'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88facedf-629b-463f-8e4d-d170c2ab348a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb19f2e-8ac6-4703-a688-17d44e8cd572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2aba1-91f4-46fd-bba8-672113dbe23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many nulls we have\n",
    "df['last_name'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f917b03b-d6fd-4109-b1ec-6098950eb836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the 'last_name' field and apply it to the field:\n",
    "\n",
    "def clean_last_name(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Common surname prefixes to normalize spacing\n",
    "    family_prefixes = {\n",
    "        \"de\", \"del\", \"de la\", \"van\", \"von\", \"da\", \"di\", \"la\", \"le\", \"du\", \"st\", \"mac\", \"mc\"\n",
    "    }\n",
    "\n",
    "    def normalize_name(name):\n",
    "        if pd.isnull(name):\n",
    "            return None\n",
    "\n",
    "        # Step 1: Normalize unicode (é → e), lowercase, strip whitespace\n",
    "        name = unicodedata.normalize(\"NFKD\", name).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "        name = name.lower().strip()\n",
    "\n",
    "        # Step 2: Remove non-alphabetic characters except space and hyphen\n",
    "        name = re.sub(r\"[^a-z\\s\\-]\", \"\", name)\n",
    "        name = re.sub(r\"\\s+\", \" \", name)\n",
    "\n",
    "        # Step 3: Normalize spacing after prefix (if present)\n",
    "        for prefix in sorted(family_prefixes, key=lambda x: -len(x)):  # longer first\n",
    "            if name.startswith(prefix + \" \"):\n",
    "                # Keep spacing; just ensure it's normalized and clean\n",
    "                name = prefix + \" \" + name[len(prefix):].strip()\n",
    "                break\n",
    "\n",
    "        return name if name else None\n",
    "\n",
    "    df[\"last_name\"] = df[\"last_name\"].apply(normalize_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = clean_last_name(df)\n",
    "\n",
    "df['last_name'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77b157-31b4-464b-946d-58763818d71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b4f86b-7a62-436a-9ff7-17cccbbe8fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a753bc2c-f295-416b-936c-214c1aefd416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many nulls we have\n",
    "df['sex'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93caaa0-9b15-483a-a8ef-611225745528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See distinct values\n",
    "df['sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee795c1d-6bf2-4740-a682-3db38dca58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See counts of distinct values\n",
    "df['sex'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d35e61a-e501-429f-8e93-b80dde23ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all occurrences of 'unknown' into null:\n",
    "df['sex'] = df['sex'].replace('unknown', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed538d52-f966-49ca-bdb4-f55f293796ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See counts of distinct values\n",
    "df['sex'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5252a5-ebfc-41de-9e27-243eb541b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all occurrences of 'unknown' into null \n",
    "# (we don't want to say two records that have sex = 'unknown' have matching values for that field):\n",
    "\n",
    "df['sex'] = df['sex'].replace('unknown', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51afc5f2-c5cf-430c-9d6c-3def2f62bdd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e48d77-377b-4737-91f3-6d5aa852b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81fd7da-b5da-48ee-8314-c63fba7d593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many nulls we have\n",
    "df['race'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62c298-de0a-4261-aa70-85617d62ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See distinct values\n",
    "df['race'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0be8e8-3665-441a-8345-154099a38f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See counts of distinct values\n",
    "df['race'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d12a90-2815-48a7-a711-7e269348e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all occurrences of unknown into null\n",
    "# (we don't want to say two records with unknown race have matching values for that field):\n",
    "\n",
    "df['race'] = df['race'].replace('unknown', np.nan)\n",
    "df['race'] = df['race'].replace('asked but unknown', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a0f85a-55e6-40f2-9982-e35067f0576f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea3428-4aa4-4397-9798-83ff1b4907e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# birth_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97943cd2-287b-4e5f-b620-0223e7450789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many nulls we have\n",
    "df['birth_date'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f24b64-d12a-481e-a808-334fa0d4c7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See distinct values\n",
    "df['birth_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f81b28-dbb7-491c-8437-5c21022957cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See counts of distinct values\n",
    "df['birth_date'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce752b-69ff-47f8-80bb-22af7e650055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice there are supsicious looking birthdays that occur frequently in the dataset:\n",
    "#     - 1900-01-01\n",
    "#     - 1901-01-01\n",
    "#     - 2001-01-01\n",
    "#     - 2000-01-01\n",
    "# These might be placeholders for null birthdays. We leave these values as they are for now, but\n",
    "# this is something to investigate at the source data level and confirm if there are values that\n",
    "# are used by different data sources as place holders for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4a972-7ab7-447c-894d-6a3e60006d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether all non-null values have the correct format\n",
    "df['birth_date'].dropna().astype(str).str.fullmatch(r'\\d{4}-\\d{2}-\\d{2}').all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7bbc25-04a5-4128-b464-596902d80398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many values we have of different lengths\n",
    "df['birth_date'].dropna().astype(str).str.len().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d77853-778a-420d-9277-7a67d0679d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd9bf0c-3b16-481a-b67f-0a84df88573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# death_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249136c4-9732-4008-a41f-5cbeb3ce6512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many nulls we have\n",
    "df['death_date'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf0c70-5c63-4a48-9d98-110bc6d81e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See distinct values\n",
    "df['death_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cf89d4-0bc6-4519-b80b-658b8827a113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See counts of distinct values\n",
    "df['death_date'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d04dfa0-b3fd-4c17-b80f-5a258efd795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether all non-null values have the correct format\n",
    "df['death_date'].dropna().astype(str).str.fullmatch(r'\\d{4}-\\d{2}-\\d{2}').all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd64f93-38c1-4486-89dd-4cc5e2459e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many values we have of different lengths\n",
    "df['death_date'].dropna().astype(str).str.len().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a54357-1130-48c9-b508-92b4efc501e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a51ba-ab4f-478d-b384-80376196fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# social_security_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a437c4-9cb1-4e84-ae3e-ba752e423030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many nulls we have\n",
    "df['social_security_number'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dccfd6-0ecc-4585-a84e-fbc75256f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many values we have of different lengths\n",
    "df['social_security_number'].dropna().astype(str).str.len().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06349482-a92e-45fc-95ab-550b2950fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the 'social_security_number' field and apply it to the field:\n",
    "\n",
    "def clean_social_security_number(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    def normalize_ssn(ssn):\n",
    "        if pd.isnull(ssn):\n",
    "            return None\n",
    "        # Convert to string and strip whitespace\n",
    "        ssn = str(ssn).strip()\n",
    "        # Remove trailing \".0\" if present\n",
    "        if ssn.endswith(\".0\"):\n",
    "            ssn = ssn[:-2]\n",
    "        # Remove non-digit characters\n",
    "        ssn = re.sub(r\"[^\\d]\", \"\", ssn)\n",
    "        # Keep only if exactly 9 digits\n",
    "        if len(ssn) == 9:\n",
    "            return ssn\n",
    "        return None\n",
    "\n",
    "    df[\"social_security_number\"] = df[\"social_security_number\"].apply(normalize_ssn)\n",
    "    return df\n",
    "\n",
    "df = clean_social_security_number(df)\n",
    "df['social_security_number'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2bf31d-3606-40d9-bac1-613b77f2c5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d236a5da-fe48-4744-8708-d6112cd86513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de95b0be-32b6-43db-992d-1e017d603dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many nulls we have\n",
    "df['address'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e63398-9055-420b-838c-11ca6cc45efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['address'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a70419-3c14-4726-aa48-2155d3ba4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the 'address' field and apply it to the field:\n",
    "\n",
    "def normalize_address(addr):\n",
    "    if pd.isnull(addr):\n",
    "        return addr  # preserve nulls\n",
    "\n",
    "    addr = addr.lower().strip()\n",
    "\n",
    "    # Remove punctuation\n",
    "    addr = re.sub(r'[^\\w\\s]', '', addr)  # remove , . # - etc.\n",
    "\n",
    "    # Normalize PO Box patterns\n",
    "    addr = re.sub(r'\\b(post office|p[\\s\\.]?o[\\s\\.]?)\\s*box\\b', 'po box', addr)\n",
    "\n",
    "    # Normalize street suffixes\n",
    "    addr = re.sub(r'\\bstreet\\b', 'st', addr)\n",
    "    addr = re.sub(r'\\bavenue\\b', 'ave', addr)\n",
    "    addr = re.sub(r'\\broad\\b', 'rd', addr)\n",
    "    addr = re.sub(r'\\bdrive\\b', 'dr', addr)\n",
    "    addr = re.sub(r'\\bboulevard\\b', 'blvd', addr)\n",
    "    addr = re.sub(r'\\blane\\b', 'ln', addr)\n",
    "    addr = re.sub(r'\\btrail\\b', 'trl', addr)\n",
    "    addr = re.sub(r'\\bplace\\b', 'pl', addr)\n",
    "    addr = re.sub(r'\\bsquare\\b', 'sq', addr)\n",
    "    addr = re.sub(r'\\bcourt\\b', 'ct', addr)\n",
    "\n",
    "    # Normalize unit and building descriptors\n",
    "    addr = re.sub(r'\\bapartment\\b', 'apt', addr)\n",
    "    addr = re.sub(r'\\bapt\\b', 'apt', addr)\n",
    "    addr = re.sub(r'\\bsuite\\b', 'ste', addr)\n",
    "    addr = re.sub(r'\\bunit\\b', 'unit', addr)\n",
    "    addr = re.sub(r'\\bbuilding\\b', 'bldg', addr)\n",
    "    addr = re.sub(r'\\broom\\b', 'rm', addr)\n",
    "\n",
    "    # Normalize directions\n",
    "    addr = re.sub(r'\\bnorth\\b', 'n', addr)\n",
    "    addr = re.sub(r'\\bsouth\\b', 's', addr)\n",
    "    addr = re.sub(r'\\beast\\b', 'e', addr)\n",
    "    addr = re.sub(r'\\bwest\\b', 'w', addr)\n",
    "\n",
    "    # Remove common stop words (add more if needed)\n",
    "    addr = re.sub(r'\\b(the|at|and|of|for)\\b', '', addr)\n",
    "\n",
    "    # Collapse multiple spaces into one\n",
    "    addr = re.sub(r'\\s+', ' ', addr)\n",
    "\n",
    "    return addr.strip()\n",
    "\n",
    "\n",
    "df['address'] = df['address'].apply(normalize_address)\n",
    "df['address'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208a74bc-6d34-4786-b20f-c34fdb6fadf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f812551-f14c-4ce8-b529-7570651e614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc2f41-6779-43f2-832e-d0f2c01a4493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many nulls we have\n",
    "df['city'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9438b678-de24-4312-92ec-322d9ddc28bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the 'city' field and apply it to the field:\n",
    "\n",
    "def normalize_city_column(df, column='city'):\n",
    "    \"\"\"\n",
    "    Clean and standardize the 'city' column of a DataFrame for record linkage.\n",
    "\n",
    "    Steps:\n",
    "    - Lowercase all values\n",
    "    - Trim leading/trailing and extra internal spaces\n",
    "    - Remove punctuation and special characters\n",
    "    - Standardize known city variants\n",
    "    - Replace junk values like 'unknown' with NaN\n",
    "    \"\"\"\n",
    "    city_aliases = {\n",
    "        'nyc': 'new york',\n",
    "        'n.y.c.': 'new york',\n",
    "        'sf': 'san francisco',\n",
    "        'la': 'los angeles',\n",
    "    }\n",
    "\n",
    "    # Convert to string, lowercase, and trim\n",
    "    df[column] = df[column].astype(str).str.lower().str.strip()\n",
    "\n",
    "    # Remove punctuation\n",
    "    df[column] = df[column].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "    # Normalize spacing\n",
    "    df[column] = df[column].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "    # Replace known aliases\n",
    "    df[column] = df[column].replace(city_aliases)\n",
    "\n",
    "    # Replace junk values with NaN\n",
    "    df[column] = df[column].replace(\n",
    "        ['unknown', 'n/a', 'null', '', 'nan'], np.nan\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = normalize_city_column(df)\n",
    "df['city'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b9a96-71c3-47ab-be85-e30c79ce5f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many nulls we have\n",
    "df['city'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0d0cab-134d-4fde-933a-5fbb2e5e0877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea8c260-0460-4e29-95c0-8b31b7718be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38ee39-9b99-46bf-baed-26bd4f2fbbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many nulls we have\n",
    "df['state'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f275e-7bba-4b7f-ad62-bd80cad0d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See unique values\n",
    "df['state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2593f6-e163-4834-a8e2-735b2ed73628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the 'state' field and apply it to the field:\n",
    "\n",
    "def clean_state_column(df, column='state'):\n",
    "    \"\"\"\n",
    "    Cleans the state column by replacing any value not in the list\n",
    "    of valid U.S. state and territory or Canadian province and territory abbreviations with NaN.\n",
    "    \"\"\"\n",
    "    valid_states = {\n",
    "        'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI',\n",
    "        'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI',\n",
    "        'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC',\n",
    "        'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT',\n",
    "        'VT', 'VA', 'WA', 'WV', 'WI', 'WY', 'AS', 'GU', 'MP', 'PR', 'VI',\n",
    "        'AB','BC','MB','NB','NL',\n",
    "        'NS','ON','PE','QC','SK',\n",
    "        'NT','NU','YT'\n",
    "    }\n",
    "\n",
    "    # Clean the column: uppercase and strip whitespace\n",
    "    df[column] = df[column].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # Replace values not in valid_states with NaN\n",
    "    df[column] = df[column].where(df[column].isin(valid_states), np.nan)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = clean_state_column(df)\n",
    "df['state'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f44e1-5410-4361-802e-755301d65f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See counts of distinct values\n",
    "df['state'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d47f363-415b-4438-a0f2-94efe31bf8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd4240-ecce-48d3-a1b5-fe3905112e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2f445a-2b61-49a8-ab1d-b1104bbe8d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many nulls we have\n",
    "df['zip_code'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e605e84-bb54-4407-8cce-0f905b9e851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See unique values\n",
    "df['zip_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0961017c-3466-409c-8080-fd1c2a4c363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many we have of different lengths\n",
    "df['zip_code'].dropna().astype(str).str.len().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc70946-6529-4476-a966-c027638c64f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the 'zip_code' field and apply it to the field:\n",
    "\n",
    "def clean_zip_code_column(df, column='zip_code', extract_5_digit=True):\n",
    "    \"\"\"\n",
    "    Cleans a ZIP code column by:\n",
    "    - Converting to string\n",
    "    - Removing trailing '.0'\n",
    "    - Removing all non-digit characters\n",
    "    - Replacing junk values\n",
    "    - Keeping only 5- or 9-digit ZIPs\n",
    "    - Optionally truncating to 5 digits\n",
    "    \"\"\"\n",
    "    # Convert to string and strip whitespace\n",
    "    df[column] = df[column].astype(str).str.strip()\n",
    "\n",
    "    # Remove trailing '.0'\n",
    "    df[column] = df[column].str.replace(r'\\.0$', '', regex=True)\n",
    "\n",
    "    # Remove non-digit characters\n",
    "    df[column] = df[column].str.replace(r'\\D', '', regex=True)\n",
    "\n",
    "    # Replace known junk values\n",
    "    df[column] = df[column].replace({'00000': np.nan, '99999': np.nan, '12345': np.nan})\n",
    "\n",
    "    # Keep only ZIPs of length 5 or 9\n",
    "    df[column] = df[column].where(df[column].str.len().isin([5, 9]), np.nan)\n",
    "\n",
    "    # Optionally truncate to first 5 digits\n",
    "    if extract_5_digit:\n",
    "        df[column] = df[column].str[:5]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = clean_zip_code_column(df)\n",
    "df['zip_code'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebee2fc-9257-4288-b343-1e40c3967f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many we have of different lengths\n",
    "df['zip_code'].dropna().astype(str).str.len().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b7b0cf-b671-4178-9b08-1939767f6ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ff43d1-dc68-4933-bd2b-90c325438cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b92da1-8e7d-40d7-bb1b-0e311bd78ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many nulls we have\n",
    "df['phone'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ca01f-f2ef-4833-89fb-6cf769f5ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See unique values\n",
    "df['phone'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aefc8d-6f7c-4cd8-ad3a-61cd4695e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many we have of different lengths\n",
    "df['phone'].dropna().astype(str).str.len().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d121b-0f83-4acc-b507-33862166d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See counts of distinct values\n",
    "df['phone'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddd761a-e539-4e9e-9585-123825e730e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that there are phone numbers that are clearly not real appearing \n",
    "# frequently in the dataset, eg.:\n",
    "#     - 5180000000\n",
    "#     - 9999999999\n",
    "# Next, when we define a function to clean 'phone' we will include logic to deal with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee858d-ae1d-471a-b40c-200dd6058b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the 'phone' field and apply it to the field:\n",
    "\n",
    "def clean_phone_column(df, column='phone', extract_10_digits=True):\n",
    "    \"\"\"\n",
    "    Cleans a phone number column by:\n",
    "    - Converting to string\n",
    "    - Removing trailing '.0'\n",
    "    - Removing non-digit characters\n",
    "    - Replacing invalid or placeholder numbers\n",
    "    - Keeping only 10-digit phone numbers (optional)\n",
    "    \"\"\"\n",
    "    # Convert to string and strip\n",
    "    df[column] = df[column].astype(str).str.strip()\n",
    "\n",
    "    # Remove trailing '.0'\n",
    "    df[column] = df[column].str.replace(r'\\.0$', '', regex=True)\n",
    "\n",
    "    # Remove all non-digit characters\n",
    "    df[column] = df[column].str.replace(r'\\D', '', regex=True)\n",
    "\n",
    "    # Replace known junk or placeholder numbers\n",
    "    df[column] = df[column].replace({\n",
    "        '0000000000': np.nan,\n",
    "        '1234567890': np.nan,\n",
    "        '1111111111': np.nan,\n",
    "        '9999999999': np.nan\n",
    "    })\n",
    "\n",
    "    # Replace values with 7+ consecutive identical digits with NaN\n",
    "    df[column] = df[column].replace(r\"(.)\\1{6,}\", np.nan, regex=True)\n",
    "\n",
    "    # Optionally ensure it's 10 digits (standard US phone length)\n",
    "    if extract_10_digits:\n",
    "        df[column] = df[column].where(df[column].str.len() == 10, np.nan)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = clean_phone_column(df)\n",
    "df['phone_number'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020893f4-b0d9-4959-a12e-fb3e6ba92cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See counts of distinct values\n",
    "df['phone'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adedb8f3-8de2-4157-aba9-fce816442cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0697e27b-fb14-4889-861a-0ceaeeb1f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505c4f6d-ebbd-44b8-9c1b-a1269a221b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc93f3d8-f8f4-4da0-b918-aa6742401a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e9117-b891-4689-ad3d-584bfd88b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **************************************************\n",
    "# Write the clean data to a CSV\n",
    "# **************************************************\n",
    "\n",
    "df.to_csv('clean_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
